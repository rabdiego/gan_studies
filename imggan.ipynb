{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorBlock(nn.Module):\n",
    "    def __init__(self, out_channels, in_channels=3, kernel_size=4, strides=2, padding=1, **kwargs):\n",
    "        super(GeneratorBlock, self).__init__(**kwargs)\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, strides, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.sequential(X)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, size, **kwargs):\n",
    "        super(Generator, self).__init__(**kwargs)\n",
    "        self.sequential = nn.Sequential(\n",
    "            GeneratorBlock(in_channels=100, out_channels=size*8, strides=1, padding=0),\n",
    "            GeneratorBlock(in_channels=size*8, out_channels=size*4),\n",
    "            GeneratorBlock(in_channels=size*4, out_channels=size*2),\n",
    "            GeneratorBlock(in_channels=size*2, out_channels=size),\n",
    "            nn.ConvTranspose2d(in_channels=size, out_channels=3, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.sequential(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Discriminator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorBlock(nn.Module):\n",
    "    def __init__(self, out_channels, in_channels=3, kernel_size=4, strides=2, padding=1, alpha=0.2, **kwargs):\n",
    "        super(DiscriminatorBlock, self).__init__(**kwargs)\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(alpha, inplace=True)\n",
    "        )\n",
    "    \n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.sequential(X)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, size, **kwargs):\n",
    "        super(Discriminator, self).__init__(**kwargs)\n",
    "        self.sequential = nn.Sequential(\n",
    "            DiscriminatorBlock(size),\n",
    "            DiscriminatorBlock(in_channels=size, out_channels=size*2),\n",
    "            DiscriminatorBlock(in_channels=size*2, out_channels=size*4),\n",
    "            DiscriminatorBlock(in_channels=size*4, out_channels=size*8),\n",
    "            nn.Conv2d(in_channels=size*8, out_channels=1, kernel_size=4, bias=False)\n",
    "        )\n",
    "    \n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.sequential(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Full GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    def __init__(self, size):\n",
    "        self.loss = None\n",
    "        self.optim_generator = None\n",
    "        self.optim_discriminator = None\n",
    "        self.latent_dim = 100\n",
    "        self.device = 'cuda'\n",
    "        self.generator = Generator(size).to(self.device)\n",
    "        self.discriminator = Discriminator(size).to(self.device)\n",
    "\n",
    "    def load(self, checkpoint_path):\n",
    "        self.discriminator.load_state_dict(torch.load(os.path.join(checkpoint_path, 'discriminator')))\n",
    "        self.generator.load_state_dict(torch.load(os.path.join(checkpoint_path, 'generator')))\n",
    "\n",
    "\n",
    "    def update_generator(self, Z):\n",
    "        batch_size = Z.shape[0]\n",
    "        ones = torch.ones((batch_size,), device=Z.device)\n",
    "\n",
    "        self.optim_generator.zero_grad()\n",
    "\n",
    "        X_fake = self.generator(Z)\n",
    "        Y_fake = self.discriminator(X_fake)\n",
    "\n",
    "        loss_generator = self.loss(Y_fake, ones.reshape(Y_fake.shape))\n",
    "\n",
    "        loss_generator.backward()\n",
    "        self.optim_generator.step()\n",
    "\n",
    "        return loss_generator\n",
    "\n",
    "\n",
    "    def update_discriminator(self, X, Z):\n",
    "        batch_size = X.shape[0]\n",
    "        ones = torch.ones((batch_size,), device=X.device)\n",
    "        zeros = torch.zeros((batch_size,), device=X.device)\n",
    "        \n",
    "        self.optim_discriminator.zero_grad()\n",
    "\n",
    "        Y_real = self.discriminator(X)\n",
    "        X_fake = self.generator(Z)\n",
    "        Y_fake = self.discriminator(X_fake.detach())\n",
    "\n",
    "        loss_discriminator = (\n",
    "            self.loss(Y_real, ones.reshape(Y_real.shape)) +\n",
    "            self.loss(Y_fake, zeros.reshape(Y_fake.shape))\n",
    "        ) / 2\n",
    "\n",
    "        loss_discriminator.backward()\n",
    "        self.optim_discriminator.step()\n",
    "\n",
    "        return loss_discriminator\n",
    "\n",
    "\n",
    "    def train(self, dataloader, num_epochs, lr, latent_dim, device, checkpoint_path=None):\n",
    "        self.loss = nn.BCEWithLogitsLoss(reduction='sum')\n",
    "        self.latent_dim = latent_dim\n",
    "        self.device = device\n",
    "\n",
    "        self.discriminator = self.discriminator.to(device)\n",
    "        self.generator = self.generator.to(device)\n",
    "\n",
    "        trainer_hp = {\n",
    "            'lr' : lr,\n",
    "            'betas' : [0.5, 0.999]\n",
    "        }\n",
    "\n",
    "        self.optim_discriminator = torch.optim.Adam(self.discriminator.parameters(), **trainer_hp)\n",
    "        self.optim_generator = torch.optim.Adam(self.generator.parameters(), **trainer_hp)\n",
    "\n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            for idx, X in enumerate(dataloader):\n",
    "                X = X.to(device)\n",
    "                Z = torch.normal(0, 1, size=(X.shape[0], latent_dim, 1, 1)).to(device)\n",
    "\n",
    "                loss_discriminator = self.update_discriminator(X, Z)\n",
    "                loss_generator = self.update_generator(Z)\n",
    "\n",
    "            print(f'Epoch {epoch}/{num_epochs} | Loss Discriminator = {loss_discriminator:3.5f} | Loss Generator = {loss_generator:3.5f}')\n",
    "\n",
    "            if checkpoint_path:\n",
    "                torch.save(self.discriminator.state_dict(), os.path.join(checkpoint_path, 'discriminator.pth'))\n",
    "                torch.save(self.generator.state_dict(), os.path.join(checkpoint_path, 'generator.pth'))\n",
    "    \n",
    "\n",
    "    def generate(self):\n",
    "        Z = torch.normal(0, 1, size=(1, self.latent_dim, 1, 1)).to(self.device)\n",
    "        Y = self.generator(Z).to('cpu').detach()[0]\n",
    "        Y_numpy = Y.numpy().transpose(1, 2, 0)\n",
    "        return Y_numpy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Transform**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((64, 64)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(0.5, 0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data_path, transform):\n",
    "        self.data_path = data_path\n",
    "        self.data_list = [os.path.join(data_path, file_name) for file_name in os.listdir(data_path)]\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_name = self.data_list[index]\n",
    "        raw_image = Image.open(file_name).convert('RGB')\n",
    "        transformed_image = self.transform(raw_image)\n",
    "        return transformed_image\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageDataset('./data', transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "loader = DataLoader(dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GAN(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(loader, 20, 0.005, 100, device, './models/model_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
